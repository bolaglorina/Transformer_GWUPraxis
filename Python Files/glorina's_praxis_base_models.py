# -*- coding: utf-8 -*-
"""Glorina's Praxis - Base_Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GJhp1UvFk5g4-p-hr5Zi3ipIlvXzBye0
"""

import pandas as pd
import numpy as numpy

import os
a = os.getcwd()
print(a)

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

ls

import os

os.chdir("/content/drive/Shared drives/Praxis_Analysis")

ls

df = pd.read_csv("Final_Clean_Data.csv")

df.head()

df.drop(columns=['Unnamed: 0'],inplace = True)

!pip install stopwords
!pip install flair
!pip install nltk
!pip install swifter

#import flair
#from flair.data import Sentence
import re
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import random as rn
import seaborn as sns
from plotly import graph_objs as go
import plotly.express as px
import plotly.figure_factory as ff
from collections import Counter
from PIL import Image
pd.options.display.max_rows = None

print(df.shape)
print(df.info())

df.email_content = df.email_content.astype('str')

df.label.value_counts()

sns.set_theme(style='whitegrid')
sns.set(rc = {'figure.figsize':(13,8)})
sns.set_palette("pastel")
sns.countplot(x="label",data=df)

txt = ' '.join(word for word in df[df['label']=='phishing'].email_content)
plt.figure(figsize=(15,8))

wordcloud = WordCloud(background_color = 'black',
                      max_font_size = 100,
                      max_words = 100,
                      width = 1000,
                      height = 600
                      ).generate(txt)

plt.imshow(wordcloud,interpolation = "bilinear")
plt.axis('off')
plt.show()
# For phishing emails, the wordcloud below shows us the top 100 most recurring words that are used in such emails

txt = ' '.join(word for word in df[df['label']=='spam'].email_content)
plt.figure(figsize=(15,8))

wordcloud = WordCloud(background_color = 'black',
                      max_font_size = 100,
                      max_words = 100,
                      width = 1000,
                      height = 600
                      ).generate(txt)

plt.imshow(wordcloud,interpolation = "bilinear")
plt.axis('off')
plt.show()
# For spam emails, the wordcloud below shows us the top 100 most recurring words that are used in such emails

# Data Cleaning
from nltk.corpus import stopwords
from nltk import WordNetLemmatizer
nltk.download('stopwords')
from nltk.stem import PorterStemmer

df.isnull().sum()

# remove duplicates
df = df.drop_duplicates(keep = 'first')

df.shape

def clean(raw):
  """ Remove hyperlinks and markup """
  result = re.sub("<[a][^>]*>(.+/)</[a]>", 'Link.',raw)
  result = re.sub('&gt;',"",result)
  result = re.sub('&#x27;',"'",result)
  result = re.sub('&quot;','"',result)
  result = re.sub('&#x2F;',' ',result)
  result = re.sub('<p>',' ',result)
  result = re.sub('</i','',result)
  result = re.sub('&#62;','',result)
  result = re.sub('<i>',' ',result)
  result = re.sub("\n",'',result)
  return result

def remove_num(texts):
  output = re.sub(r'\d+','',texts)
  return output

def deEmojify(x):
  regrex_pattern = re.compile(pattern = "["
  u"\U0001F600-\U0001F64F"
  u"\U0001F300-\U0001F5FF"
  u"\U0001F680-\U0001F6FF"
  u"\U0001F1E0-\U0001F1FF"
  "]+", flags = re.UNICODE)
  return regrex_pattern.sub(r'',x)

def remove_symbols(x):
  cleaned_string = re.sub(r"[^a-zA-Z0-9?!.,]+",' ',x)
  return cleaned_string

def unify_whitespaces(x):
  cleaned_string = re.sub(' +',' ',x)
  return cleaned_string

def remove_punctuation(text):
  final = "".join(u for u in text if u not in ("?",".",";",":","!",'"',","))
  return final

stop = set(stopwords.words("english"))
stemmer = PorterStemmer()
lemma = WordNetLemmatizer()

def remove_stopword(text):
  text = [word.lower() for word in text.split() if word.lower() not in stop]
  return " ".join(text)

from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
def Stemming(text):
  stem = []
  stopword = stopwords.words('english')
  snowball_stemmer = SnowballStemmer('english')
  word_tokens = nltk.word_tokenize(text)
  stemmed_word = [snowball_stemmer.stem(word) for word in word_tokens]
  stem = " ".join(stemmed_word)
  return stem

import nltk
nltk.download('punkt')

def cleaning(df, review):
  df[review] = df[review].apply(clean)
  df[review] = df[review].apply(deEmojify)
  df[review] = df[review].str.lower()
  df[review] = df[review].apply(remove_num)
  df[review] = df[review].apply(remove_symbols)
  df[review] = df[review].apply(remove_punctuation)
  df[review] = df[review].apply(remove_stopword)
  df[review] = df[review].apply(unify_whitespaces)
  df[review] = df[review].apply(Stemming)

cleaning(df,'email_content')

# Random Forest Classifier as our modeling algorithm
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
clf = Pipeline([
    ('vect', CountVectorizer(stop_words= "english",max_features=5000)),
    ('tfidf', TfidfTransformer()),
    ('classifier', RandomForestClassifier()),
    ])

df.label = df.label.replace({'phishing':1,'spam':0})

X = df['email_content']
y = df['label']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 40,
                                                   test_size = 0.20)
text_classifier = clf.fit(X_train,y_train)
predictions = text_classifier.predict(X_test)

# Model performance
# confusion  matrix - Diagonal elements tell you the correct number of predictions.
# The first element tells you the number of emails that were not phishing and were not identified as phishing -indicating correct prediction
# The second element tells you the number of emails that were actually phishing and the model identified them as phishing. indicating correct prediction

from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score
confusion_matrix(y_test,predictions)

# Model performance - Accuracy can be used as a model evaluation since the dataset is balanced.
def results(y_test,y_pred):

  print('Classification Report: \n',classification_report(y_test,predictions,labels=[1,0]))
  print("F1-Score: {}".format(f1_score(y_test,y_pred,average="macro")))
  print("ROC-AUC {}".format(roc_auc_score(y_test,y_pred)))
results(y_test,predictions)

# Logistic Regression Model
from sklearn.linear_model import LogisticRegression
clf_log = Pipeline([
    ('vect', CountVectorizer(stop_words= "english",max_features=5000)),
    ('tfidf', TfidfTransformer()),
    ('classifier', LogisticRegression()),
    ])

#df.label = df.label.replace({'phishing':1,'spam':0})

X = df['email_content']
y = df['label']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 40,
                                                   test_size = 0.20)
text_classifier = clf_log.fit(X_train,y_train)
predictions = text_classifier.predict(X_test)

# Model performance
# confusion  matrix - Diagonal elements tell you the correct number of predictions.
# The first element tells you the number of emails that were not phishing and were not identified as phishing -indicating correct prediction
# The second element tells you the number of emails that were actually phishing and the model identified them as phishing. indicating correct prediction

from sklearn.metrics import confusion_matrix,classification_report
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, roc_auc_score
confusion_matrix(y_test,predictions)

# Model performance - Accuracy can be used as a model evaluation since the dataset is balanced.
def results(y_test,y_pred):

  print('Classification Report: \n',classification_report(y_test,predictions,labels=[1,0]))
  print("F1-Score: {}".format(f1_score(y_test,y_pred,average="macro")))
  print("ROC-AUC {}".format(roc_auc_score(y_test,y_pred)))
results(y_test,predictions)